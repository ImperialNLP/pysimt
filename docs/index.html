<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pysimt API documentation</title>
<meta name="description" content="`pysimt` is a `PyTorch`-based sequence-to-sequence (S2S) framework that facilitates
research in unimodal and multi-modal machine translation. The â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>pysimt</code></h1>
</header>
<section id="section-intro">
<p><code><a title="pysimt" href="#pysimt">pysimt</a></code> is a <code>PyTorch</code>-based sequence-to-sequence (S2S) framework that facilitates
research in unimodal and multi-modal machine translation. The framework
is especially geared towards a set of recent simultaneous MT approaches, including
heuristics-based decoding and prefix-to-prefix training/decoding. Common metrics
such as average proportion (AP), average lag (AL), and consecutive wait (CW)
are provided through well-defined APIs as well.</p>
<h2 id="features">Features</h2>
<p><code><a title="pysimt" href="#pysimt">pysimt</a></code> includes two state-of-the-art S2S approaches to neural machine
translation (NMT) to begin with:</p>
<ul>
<li><a href="http://arxiv.org/pdf/1409.0473">RNN-based attentive NMT (Bahdanau et al. 2014)</a></li>
<li><a href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">Self-attention based Transformers NMT (Vaswani et al. 2017)</a></li>
</ul>
<p>The toolkit mostly emphasizes on multimodal machine translation (MMT), and
therefore the above models easily accomodate multiple source modalities
through <a href="https://www.aclweb.org/anthology/2020.emnlp-main.184">encoder-side (Caglayan et al. 2020)</a> and <a href="http://arxiv.org/pdf/1609.03976">decoder-side multimodal attention (Caglayan et al. 2016)</a> approaches.</p>
<h3 id="simultaneous-nmt">Simultaneous NMT</h3>
<p>The following notable approaches in the simultaneous NMT field are implemented:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1606.02012">Heuristics-based decoding approaches wait-if-diff and wait-if-worse (Cho and Esipova, 2016)</a></li>
<li><a href="https://www.aclweb.org/anthology/P19-1289.pdf">Prefix-to-prefix training and decoding approach wait-k (Ma et al., 2019)</a></li>
</ul>
<h3 id="simultaneous-mmt">Simultaneous MMT</h3>
<p>The toolkit includes the reference implementation for the following conference
papers that initiated research in Simultaneous MMT:</p>
<ul>
<li><a href="https://www.aclweb.org/anthology/2020.emnlp-main.184.pdf">Simultaneous Machine Translation with Visual Context (Caglayan et al. 2020)</a></li>
<li><a href="http://statmt.org/wmt20/pdf/2020.wmt-1.70.pdf">Towards Multimodal Simultaneous Neural Machine Translation (Imankulova et al. 2020)</a></li>
</ul>
<h3 id="other-features">Other features</h3>
<ul>
<li>CPU / (Single) GPU training of sequence-to-sequence frameworks</li>
<li>Reproducible experimentation through well-defined configuration files</li>
<li>Easy multimodal training with parallel corpora</li>
<li>Logging training progress and validation performance to Tensorboard</li>
<li>Text, Image Features and Speech encoders</li>
<li>Early-stopping and model checkpointing using various criteria such as MultiBLEU,
SacreBLEU, METEOR, word error rate (WER), character error rate (CER), etc.</li>
<li>Ready-to-use latency metrics for simultaneous MT, including average proportion (AP),
average lag (AL), and consecutive wait (CW)</li>
<li>Beam search translation for consecutive, greedy search translation for simultaneous MT</li>
<li>Utilities to produce reports for simultaneous MT performance</li>
</ul>
<h2 id="installation">Installation</h2>
<p>Essentially, <code><a title="pysimt" href="#pysimt">pysimt</a></code> requires <code>Python&gt;=3.7</code> and <code>torch&gt;=1.7.0</code>. You can access
the other dependencies in the provided <code>environment.yml</code> file.</p>
<p>The following command will create an appropriate Anaconda environment with <code><a title="pysimt" href="#pysimt">pysimt</a></code>
installed in editable mode. This will allow you to modify to code in the GIT
checkout folder, and then run the experiments directly.</p>
<pre><code>$ conda env create -f environment.yml
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you want to use the METEOR metric for early-stopping or the <code>pysimt-coco-metrics</code>
script to evaluate your models' performance, you need to run the <code>pysimt-install-extra</code>
script within the <strong>pysimt</strong> Anaconda environment. This will download and install
the METEOR paraphrase files under the <code>~/.pysimt</code> folder.</p>
</div>
<h2 id="command-line-tools">Command-line tools</h2>
<p>Once installed, you will have access to three command line utilities:</p>
<h3 id="pysimt-build-vocab">pysimt-build-vocab</h3>
<ul>
<li>Since <code><a title="pysimt" href="#pysimt">pysimt</a></code> does not pre-process, tokenize, segment the given text files
automagically, all these steps should be done by the user prior to training, and
the relevant vocabulary files should be constructed using <code>pysimt-build-vocab</code>.</li>
<li>Different vocabularies should be constructed for source and target language
representations (unless <code>-s</code> is given).</li>
<li>The resulting files are in <code>.json</code> format.</li>
</ul>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>-o, --output-dir OUTPUT_DIR</code>: Output directory where the resulting vocabularies will be stored.</li>
<li><code>-s, --single</code>: If given, a single vocabulary file for all the
given training corpora files will be constructed. Useful for weight tying in embedding layers.</li>
<li><code>-m, --min-freq</code>: If given an integer <code>M</code>, it will filter out tokens occuring <code>&lt; M</code> times.</li>
<li><code>-M, --max-items</code>: If given an integer <code>M</code>, the final vocabulary will be limited to <code>M</code> most-frequent tokens.</li>
<li><code>-x, --exclude-symbols</code>: If given, the vocabulary will <strong>not include special markers</strong> such as <code>&lt;bos&gt;, &lt;eos&gt;</code>.
This should be used cautiously, and only for ad-hoc model implementations, as it may break the default models.</li>
<li><code>files</code>: A variable number of training set corpora can be provided. If <code>-s</code> is not
given, one vocabulary for each will be created.</li>
</ul>
<h3 id="pysimt-coco-metrics">pysimt-coco-metrics</h3>
<p>This is a simple utility that computes BLEU, METEOR, CIDEr, and ROUGE-L
using the well known <a href="https://github.com/tylin/coco-caption">coco-caption</a> library. The library is shipped within
<code><a title="pysimt" href="#pysimt">pysimt</a></code> so that you do not have to install it separately.</p>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>-l, --language</code>: If given a string <code>L</code>, the METEOR will be informed with that information.
For languages not supported by METEOR, English will be assumed.</li>
<li><code>-w, --write</code>: For every hypothesis file given as argument, a <code>&lt;hypothesis file&gt;.score</code> file
will be created with the computed metrics inside for convenience.</li>
<li><code>-r, --refs</code>: List of reference files for evaluation. The number of lines across multiple
references should be <strong>equal</strong>.</li>
<li><code>systems</code>: A variable number of hypotheses files that represent system outputs.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code>$ pysimt-coco-metrics -l de system1.hyps system2.hyps -r ref1
$ pysimt-coco-metrics -l de system1.hyps system2.hyps -r ref1 ref2 ref3
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This utility requires <strong>tokenized</strong> hypotheses and references, as further
tokenization is not applied by the internal metrics. Specifically for BLEU,
if you are not evaluating your models for MMT or image captioning,
you may want to use <code>sacreBLEU</code> for detokenized hypotheses and references.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The <code>Bleu_4</code> produced by this utility is equivalent to the output of
<code>multi-bleu.perl</code> and <code>sacreBLEU</code> (when <code>--tokenize none</code> is given to the latter).</p>
</div>
<h3 id="pysimt">pysimt</h3>
<p>This is the main entry point to the software. It supports two modes, namely
<strong>pysimt train</strong> and <strong>pysimt translate</strong>.</p>
<h4 id="training-a-model">Training a model</h4>
<h4 id="translating-with-a-pre-trained-model">Translating with a pre-trained model</h4>
<h2 id="configuring-an-experiment">Configuring An Experiment</h2>
<h2 id="models">Models</h2>
<ul>
<li>A <code><a title="pysimt" href="#pysimt">pysimt</a></code> model derives from <code>torch.nn.Module</code> and implements specific API methods.</li>
</ul>
<h2 id="contributing">Contributing</h2>
<p><code><a title="pysimt" href="#pysimt">pysimt</a></code> is <a href="https://github.com/ImperialNLP/pysimt">on GitHub</a>. Bug reports and pull requests are welcome.</p>
<h2 id="citing-the-toolkit">Citing The Toolkit</h2>
<p>As of now, you can cite the <a href="https://www.aclweb.org/anthology/2020.emnlp-main.184">following work</a> if you use this toolkit. We will
update this section if the software paper is published elsewhere.</p>
<pre><code>@inproceedings{caglayan-etal-2020-simultaneous,
  title = &quot;Simultaneous Machine Translation with Visual Context&quot;,
  author = {Caglayan, Ozan  and
    Ive, Julia  and
    Haralampieva, Veneta  and
    Madhyastha, Pranava  and
    Barrault, Lo{\&quot;\i}c  and
    Specia, Lucia},
  booktitle = &quot;Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)&quot;,
  month = nov,
  year = &quot;2020&quot;,
  address = &quot;Online&quot;,
  publisher = &quot;Association for Computational Linguistics&quot;,
  url = &quot;https://www.aclweb.org/anthology/2020.emnlp-main.184&quot;,
  pages = &quot;2350--2361&quot;,
}
</code></pre>
<h2 id="license">License</h2>
<p><code><a title="pysimt" href="#pysimt">pysimt</a></code> uses MIT License.</p>
<pre><code>Copyright (c) 2020 NLP@Imperial

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &quot;Software&quot;), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</code></pre>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
`pysimt` is a `PyTorch`-based sequence-to-sequence (S2S) framework that facilitates
research in unimodal and multi-modal machine translation. The framework
is especially geared towards a set of recent simultaneous MT approaches, including
heuristics-based decoding and prefix-to-prefix training/decoding. Common metrics
such as average proportion (AP), average lag (AL), and consecutive wait (CW)
are provided through well-defined APIs as well.


.. include:: ./docs.md
&#34;&#34;&#34;

__version__ = &#39;1.0.0&#39;

# Disable documentation generation for the following sub modules
__pdoc__ = {
    &#39;cocoeval&#39;: False,
    &#39;config&#39;: False,
    &#39;logger&#39;: False,
}</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="pysimt.datasets" href="datasets/index.html">pysimt.datasets</a></code></dt>
<dd>
<div class="desc"><p>A dataset in <code><a title="pysimt" href="#pysimt">pysimt</a></code> inherits from <code>torch.nn.Dataset</code> and is designed
to read and expose a specific type of corpus â€¦</p></div>
</dd>
<dt><code class="name"><a title="pysimt.evaluator" href="evaluator.html">pysimt.evaluator</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.layers" href="layers/index.html">pysimt.layers</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.lr_scheduler" href="lr_scheduler.html">pysimt.lr_scheduler</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.mainloop" href="mainloop.html">pysimt.mainloop</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.metrics" href="metrics/index.html">pysimt.metrics</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.models" href="models/index.html">pysimt.models</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.monitor" href="monitor.html">pysimt.monitor</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.optimizer" href="optimizer.html">pysimt.optimizer</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.samplers" href="samplers/index.html">pysimt.samplers</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.stranslator" href="stranslator.html">pysimt.stranslator</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.translators" href="translators/index.html">pysimt.translators</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.utils" href="utils/index.html">pysimt.utils</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="pysimt.vocabulary" href="vocabulary.html">pysimt.vocabulary</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#features">Features</a><ul>
<li><a href="#simultaneous-nmt">Simultaneous NMT</a></li>
<li><a href="#simultaneous-mmt">Simultaneous MMT</a></li>
<li><a href="#other-features">Other features</a></li>
</ul>
</li>
<li><a href="#installation">Installation</a></li>
<li><a href="#command-line-tools">Command-line tools</a><ul>
<li><a href="#pysimt-build-vocab">pysimt-build-vocab</a></li>
<li><a href="#pysimt-coco-metrics">pysimt-coco-metrics</a></li>
<li><a href="#pysimt">pysimt</a><ul>
<li><a href="#training-a-model">Training a model</a></li>
<li><a href="#translating-with-a-pre-trained-model">Translating with a pre-trained model</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#configuring-an-experiment">Configuring an experiment</a></li>
<li><a href="#models">Models</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#citing-the-toolkit">Citing the toolkit</a></li>
<li><a href="#license">License</a></li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="pysimt.datasets" href="datasets/index.html">pysimt.datasets</a></code></li>
<li><code><a title="pysimt.evaluator" href="evaluator.html">pysimt.evaluator</a></code></li>
<li><code><a title="pysimt.layers" href="layers/index.html">pysimt.layers</a></code></li>
<li><code><a title="pysimt.lr_scheduler" href="lr_scheduler.html">pysimt.lr_scheduler</a></code></li>
<li><code><a title="pysimt.mainloop" href="mainloop.html">pysimt.mainloop</a></code></li>
<li><code><a title="pysimt.metrics" href="metrics/index.html">pysimt.metrics</a></code></li>
<li><code><a title="pysimt.models" href="models/index.html">pysimt.models</a></code></li>
<li><code><a title="pysimt.monitor" href="monitor.html">pysimt.monitor</a></code></li>
<li><code><a title="pysimt.optimizer" href="optimizer.html">pysimt.optimizer</a></code></li>
<li><code><a title="pysimt.samplers" href="samplers/index.html">pysimt.samplers</a></code></li>
<li><code><a title="pysimt.stranslator" href="stranslator.html">pysimt.stranslator</a></code></li>
<li><code><a title="pysimt.translators" href="translators/index.html">pysimt.translators</a></code></li>
<li><code><a title="pysimt.utils" href="utils/index.html">pysimt.utils</a></code></li>
<li><code><a title="pysimt.vocabulary" href="vocabulary.html">pysimt.vocabulary</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>