<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pysimt.cocoeval.cider.cider_scorer API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysimt.cocoeval.cider.cider_scorer</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# Tsung-Yi Lin &lt;tl483@cornell.edu&gt;
# Ramakrishna Vedantam &lt;vrama91@vt.edu&gt;

import math
import copy
from collections import defaultdict

import numpy as np


def precook(s, n=4, out=False):
    &#34;&#34;&#34;
    Takes a string as input and returns an object that can be given to
    either cook_refs or cook_test. This is optional: cook_refs and cook_test
    can take string arguments as well.
    :param s: string : sentence to be converted into ngrams
    :param n: int    : number of ngrams for which representation is calculated
    :return: term frequency vector for occuring ngrams
    &#34;&#34;&#34;
    words = s.split()
    counts = defaultdict(int)
    for k in range(1, n + 1):
        for i in range(len(words) - k + 1):
            ngram = tuple(words[i: i + k])
            counts[ngram] += 1
    return counts


def cook_refs(refs, n=4):
    # lhuang: oracle will call with &#34;average&#34;
    &#39;&#39;&#39;Takes a list of reference sentences for a single segment
    and returns an object that encapsulates everything that BLEU
    needs to know about them.
    :param refs: list of string : reference sentences for some image
    :param n: int : number of ngrams for which (ngram) repr. is calculated
    :return: result (list of dict)
    &#39;&#39;&#39;
    return [precook(ref, n) for ref in refs]


def cook_test(test, n=4):
    &#39;&#39;&#39;Takes a test sentence and returns an object that
    encapsulates everything that BLEU needs to know about it.
    :param test: list of string : hypothesis sentence for some image
    :param n: int : number of ngrams for which (ngram) repr. is calculated
    :return: result (dict)
    &#39;&#39;&#39;
    return precook(test, n, True)


class CiderScorer:
    &#34;&#34;&#34;CIDEr scorer.&#34;&#34;&#34;

    def copy(self):
        &#39;&#39;&#39; copy the refs.&#39;&#39;&#39;
        new = CiderScorer(n=self.n)
        new.ctest = copy.copy(self.ctest)
        new.crefs = copy.copy(self.crefs)
        return new

    def __init__(self, test=None, refs=None, n=4, sigma=6.0):
        &#34;&#34;&#34;singular instance&#34;&#34;&#34;
        self.n = n
        self.sigma = sigma
        self.crefs = []
        self.ctest = []
        self.document_frequency = defaultdict(float)
        self.cook_append(test, refs)
        self.ref_len = None

    def cook_append(self, test, refs):
        &#39;&#39;&#39;called by constructor and __iadd__ to avoid
        creating new instances.&#39;&#39;&#39;

        if refs is not None:
            self.crefs.append(cook_refs(refs))
            if test is not None:
                self.ctest.append(cook_test(test))  # N.B.: -1
            else:
                # lens of crefs and ctest have to match
                self.ctest.append(None)

    def size(self):
        assert len(self.crefs) == len(self.ctest), \
            &#34;refs/test mismatch! %d&lt;&gt;%d&#34; % (len(self.crefs), len(self.ctest))
        return len(self.crefs)

    def __iadd__(self, other):
        &#39;&#39;&#39;add an instance (e.g., from another sentence).&#39;&#39;&#39;

        if isinstance(other, tuple):
            # avoid creating new CiderScorer instances
            self.cook_append(other[0], other[1])
        else:
            self.ctest.extend(other.ctest)
            self.crefs.extend(other.crefs)
        return self

    def compute_doc_freq(self):
        &#39;&#39;&#39;
        Compute term frequency for reference data.
        This will be used to compute idf (inverse document frequency later)
        The term frequency is stored in the object
        :return: None
        &#39;&#39;&#39;
        for refs in self.crefs:
            # refs, k ref captions of one image
            for ngram in set([ngram for ref in refs for (ngram, count) in ref.items()]):
                self.document_frequency[ngram] += 1
            # maxcounts[ngram] = max(maxcounts.get(ngram,0), count)

    def compute_cider(self):
        def counts2vec(cnts):
            &#34;&#34;&#34;
            Function maps counts of ngram to vector of tfidf weights.
            The function returns vec, an array of dictionary that store
            mapping of n-gram and tf-idf weights.
            The n-th entry of array denotes length of n-grams.
            :param cnts:
            :return: vec (array of dict), norm (array of float), length (int)
            &#34;&#34;&#34;
            vec = [defaultdict(float) for _ in range(self.n)]
            length = 0
            norm = [0.0 for _ in range(self.n)]
            for (ngram, term_freq) in cnts.items():
                # give word count 1 if it doesn&#39;t appear in reference corpus
                df = np.log(max(1.0, self.document_frequency[ngram]))
                # ngram index
                n = len(ngram) - 1
                # tf (term_freq) * idf (precomputed idf) for n-grams
                vec[n][ngram] = float(term_freq) * (self.ref_len - df)
                # compute norm for the vector
                # the norm will be used for computing similarity
                norm[n] += pow(vec[n][ngram], 2)

                if n == 1:
                    length += term_freq
            norm = [np.sqrt(n) for n in norm]
            return vec, norm, length

        def sim(vec_hyp, vec_ref, norm_hyp, norm_ref, length_hyp, length_ref):
            &#39;&#39;&#39;
            Compute the cosine similarity of two vectors.
            :param vec_hyp: array of dictionary for hypothesis vector
            :param vec_ref: array of dictionary for reference vector
            :param norm_hyp: array of float for hypothesis vector
            :param norm_ref: array of float for reference vector
            :param length_hyp: int containing length of hypothesis
            :param length_ref: int containing length of reference
            :return: array of score for each n-grams cosine similarity
            &#39;&#39;&#39;
            delta = float(length_hyp - length_ref)
            # measure consine similarity
            val = np.array([0.0 for _ in range(self.n)])
            for n in range(self.n):
                # ngram
                for (ngram, count) in vec_hyp[n].items():
                    # vrama91 : added clipping
                    val[n] += min(vec_hyp[n][ngram],
                                  vec_ref[n][ngram]) * vec_ref[n][ngram]

                if (norm_hyp[n] != 0) and (norm_ref[n] != 0):
                    val[n] /= (norm_hyp[n] * norm_ref[n])

                assert not math.isnan(val[n])
                # vrama91: added a length based gaussian penalty
                val[n] *= np.e**(-(delta**2) / (2 * self.sigma**2))
            return val

        # compute log reference length
        self.ref_len = np.log(float(len(self.crefs)))

        scores = []
        for test, refs in zip(self.ctest, self.crefs):
            # compute vector for test captions
            vec, norm, length = counts2vec(test)
            # compute vector for ref captions
            score = np.array([0.0 for _ in range(self.n)])
            for ref in refs:
                vec_ref, norm_ref, length_ref = counts2vec(ref)
                score += sim(vec, vec_ref, norm, norm_ref, length, length_ref)
            # change by vrama91 - mean of ngram scores, instead of sum
            score_avg = np.mean(score)
            # divide by number of references
            score_avg /= len(refs)
            # multiply score by 10
            score_avg *= 10.0
            # append score of an image to the score list
            scores.append(score_avg)
        return scores

    def compute_score(self, option=None, verbose=0):
        # compute idf
        self.compute_doc_freq()
        # assert to check document frequency
        assert len(self.ctest) &gt;= max(self.document_frequency.values())
        # compute cider score
        score = self.compute_cider()
        return np.mean(np.array(score)), np.array(score)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pysimt.cocoeval.cider.cider_scorer.cook_refs"><code class="name flex">
<span>def <span class="ident">cook_refs</span></span>(<span>refs, n=4)</span>
</code></dt>
<dd>
<div class="desc"><p>Takes a list of reference sentences for a single segment
and returns an object that encapsulates everything that BLEU
needs to know about them.
:param refs: list of string : reference sentences for some image
:param n: int : number of ngrams for which (ngram) repr. is calculated
:return: result (list of dict)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cook_refs(refs, n=4):
    # lhuang: oracle will call with &#34;average&#34;
    &#39;&#39;&#39;Takes a list of reference sentences for a single segment
    and returns an object that encapsulates everything that BLEU
    needs to know about them.
    :param refs: list of string : reference sentences for some image
    :param n: int : number of ngrams for which (ngram) repr. is calculated
    :return: result (list of dict)
    &#39;&#39;&#39;
    return [precook(ref, n) for ref in refs]</code></pre>
</details>
</dd>
<dt id="pysimt.cocoeval.cider.cider_scorer.cook_test"><code class="name flex">
<span>def <span class="ident">cook_test</span></span>(<span>test, n=4)</span>
</code></dt>
<dd>
<div class="desc"><p>Takes a test sentence and returns an object that
encapsulates everything that BLEU needs to know about it.
:param test: list of string : hypothesis sentence for some image
:param n: int : number of ngrams for which (ngram) repr. is calculated
:return: result (dict)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cook_test(test, n=4):
    &#39;&#39;&#39;Takes a test sentence and returns an object that
    encapsulates everything that BLEU needs to know about it.
    :param test: list of string : hypothesis sentence for some image
    :param n: int : number of ngrams for which (ngram) repr. is calculated
    :return: result (dict)
    &#39;&#39;&#39;
    return precook(test, n, True)</code></pre>
</details>
</dd>
<dt id="pysimt.cocoeval.cider.cider_scorer.precook"><code class="name flex">
<span>def <span class="ident">precook</span></span>(<span>s, n=4, out=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Takes a string as input and returns an object that can be given to
either cook_refs or cook_test. This is optional: cook_refs and cook_test
can take string arguments as well.
:param s: string : sentence to be converted into ngrams
:param n: int
: number of ngrams for which representation is calculated
:return: term frequency vector for occuring ngrams</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def precook(s, n=4, out=False):
    &#34;&#34;&#34;
    Takes a string as input and returns an object that can be given to
    either cook_refs or cook_test. This is optional: cook_refs and cook_test
    can take string arguments as well.
    :param s: string : sentence to be converted into ngrams
    :param n: int    : number of ngrams for which representation is calculated
    :return: term frequency vector for occuring ngrams
    &#34;&#34;&#34;
    words = s.split()
    counts = defaultdict(int)
    for k in range(1, n + 1):
        for i in range(len(words) - k + 1):
            ngram = tuple(words[i: i + k])
            counts[ngram] += 1
    return counts</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pysimt.cocoeval.cider.cider_scorer.CiderScorer"><code class="flex name class">
<span>class <span class="ident">CiderScorer</span></span>
<span>(</span><span>test=None, refs=None, n=4, sigma=6.0)</span>
</code></dt>
<dd>
<div class="desc"><p>CIDEr scorer.</p>
<p>singular instance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CiderScorer:
    &#34;&#34;&#34;CIDEr scorer.&#34;&#34;&#34;

    def copy(self):
        &#39;&#39;&#39; copy the refs.&#39;&#39;&#39;
        new = CiderScorer(n=self.n)
        new.ctest = copy.copy(self.ctest)
        new.crefs = copy.copy(self.crefs)
        return new

    def __init__(self, test=None, refs=None, n=4, sigma=6.0):
        &#34;&#34;&#34;singular instance&#34;&#34;&#34;
        self.n = n
        self.sigma = sigma
        self.crefs = []
        self.ctest = []
        self.document_frequency = defaultdict(float)
        self.cook_append(test, refs)
        self.ref_len = None

    def cook_append(self, test, refs):
        &#39;&#39;&#39;called by constructor and __iadd__ to avoid
        creating new instances.&#39;&#39;&#39;

        if refs is not None:
            self.crefs.append(cook_refs(refs))
            if test is not None:
                self.ctest.append(cook_test(test))  # N.B.: -1
            else:
                # lens of crefs and ctest have to match
                self.ctest.append(None)

    def size(self):
        assert len(self.crefs) == len(self.ctest), \
            &#34;refs/test mismatch! %d&lt;&gt;%d&#34; % (len(self.crefs), len(self.ctest))
        return len(self.crefs)

    def __iadd__(self, other):
        &#39;&#39;&#39;add an instance (e.g., from another sentence).&#39;&#39;&#39;

        if isinstance(other, tuple):
            # avoid creating new CiderScorer instances
            self.cook_append(other[0], other[1])
        else:
            self.ctest.extend(other.ctest)
            self.crefs.extend(other.crefs)
        return self

    def compute_doc_freq(self):
        &#39;&#39;&#39;
        Compute term frequency for reference data.
        This will be used to compute idf (inverse document frequency later)
        The term frequency is stored in the object
        :return: None
        &#39;&#39;&#39;
        for refs in self.crefs:
            # refs, k ref captions of one image
            for ngram in set([ngram for ref in refs for (ngram, count) in ref.items()]):
                self.document_frequency[ngram] += 1
            # maxcounts[ngram] = max(maxcounts.get(ngram,0), count)

    def compute_cider(self):
        def counts2vec(cnts):
            &#34;&#34;&#34;
            Function maps counts of ngram to vector of tfidf weights.
            The function returns vec, an array of dictionary that store
            mapping of n-gram and tf-idf weights.
            The n-th entry of array denotes length of n-grams.
            :param cnts:
            :return: vec (array of dict), norm (array of float), length (int)
            &#34;&#34;&#34;
            vec = [defaultdict(float) for _ in range(self.n)]
            length = 0
            norm = [0.0 for _ in range(self.n)]
            for (ngram, term_freq) in cnts.items():
                # give word count 1 if it doesn&#39;t appear in reference corpus
                df = np.log(max(1.0, self.document_frequency[ngram]))
                # ngram index
                n = len(ngram) - 1
                # tf (term_freq) * idf (precomputed idf) for n-grams
                vec[n][ngram] = float(term_freq) * (self.ref_len - df)
                # compute norm for the vector
                # the norm will be used for computing similarity
                norm[n] += pow(vec[n][ngram], 2)

                if n == 1:
                    length += term_freq
            norm = [np.sqrt(n) for n in norm]
            return vec, norm, length

        def sim(vec_hyp, vec_ref, norm_hyp, norm_ref, length_hyp, length_ref):
            &#39;&#39;&#39;
            Compute the cosine similarity of two vectors.
            :param vec_hyp: array of dictionary for hypothesis vector
            :param vec_ref: array of dictionary for reference vector
            :param norm_hyp: array of float for hypothesis vector
            :param norm_ref: array of float for reference vector
            :param length_hyp: int containing length of hypothesis
            :param length_ref: int containing length of reference
            :return: array of score for each n-grams cosine similarity
            &#39;&#39;&#39;
            delta = float(length_hyp - length_ref)
            # measure consine similarity
            val = np.array([0.0 for _ in range(self.n)])
            for n in range(self.n):
                # ngram
                for (ngram, count) in vec_hyp[n].items():
                    # vrama91 : added clipping
                    val[n] += min(vec_hyp[n][ngram],
                                  vec_ref[n][ngram]) * vec_ref[n][ngram]

                if (norm_hyp[n] != 0) and (norm_ref[n] != 0):
                    val[n] /= (norm_hyp[n] * norm_ref[n])

                assert not math.isnan(val[n])
                # vrama91: added a length based gaussian penalty
                val[n] *= np.e**(-(delta**2) / (2 * self.sigma**2))
            return val

        # compute log reference length
        self.ref_len = np.log(float(len(self.crefs)))

        scores = []
        for test, refs in zip(self.ctest, self.crefs):
            # compute vector for test captions
            vec, norm, length = counts2vec(test)
            # compute vector for ref captions
            score = np.array([0.0 for _ in range(self.n)])
            for ref in refs:
                vec_ref, norm_ref, length_ref = counts2vec(ref)
                score += sim(vec, vec_ref, norm, norm_ref, length, length_ref)
            # change by vrama91 - mean of ngram scores, instead of sum
            score_avg = np.mean(score)
            # divide by number of references
            score_avg /= len(refs)
            # multiply score by 10
            score_avg *= 10.0
            # append score of an image to the score list
            scores.append(score_avg)
        return scores

    def compute_score(self, option=None, verbose=0):
        # compute idf
        self.compute_doc_freq()
        # assert to check document frequency
        assert len(self.ctest) &gt;= max(self.document_frequency.values())
        # compute cider score
        score = self.compute_cider()
        return np.mean(np.array(score)), np.array(score)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_cider"><code class="name flex">
<span>def <span class="ident">compute_cider</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_cider(self):
    def counts2vec(cnts):
        &#34;&#34;&#34;
        Function maps counts of ngram to vector of tfidf weights.
        The function returns vec, an array of dictionary that store
        mapping of n-gram and tf-idf weights.
        The n-th entry of array denotes length of n-grams.
        :param cnts:
        :return: vec (array of dict), norm (array of float), length (int)
        &#34;&#34;&#34;
        vec = [defaultdict(float) for _ in range(self.n)]
        length = 0
        norm = [0.0 for _ in range(self.n)]
        for (ngram, term_freq) in cnts.items():
            # give word count 1 if it doesn&#39;t appear in reference corpus
            df = np.log(max(1.0, self.document_frequency[ngram]))
            # ngram index
            n = len(ngram) - 1
            # tf (term_freq) * idf (precomputed idf) for n-grams
            vec[n][ngram] = float(term_freq) * (self.ref_len - df)
            # compute norm for the vector
            # the norm will be used for computing similarity
            norm[n] += pow(vec[n][ngram], 2)

            if n == 1:
                length += term_freq
        norm = [np.sqrt(n) for n in norm]
        return vec, norm, length

    def sim(vec_hyp, vec_ref, norm_hyp, norm_ref, length_hyp, length_ref):
        &#39;&#39;&#39;
        Compute the cosine similarity of two vectors.
        :param vec_hyp: array of dictionary for hypothesis vector
        :param vec_ref: array of dictionary for reference vector
        :param norm_hyp: array of float for hypothesis vector
        :param norm_ref: array of float for reference vector
        :param length_hyp: int containing length of hypothesis
        :param length_ref: int containing length of reference
        :return: array of score for each n-grams cosine similarity
        &#39;&#39;&#39;
        delta = float(length_hyp - length_ref)
        # measure consine similarity
        val = np.array([0.0 for _ in range(self.n)])
        for n in range(self.n):
            # ngram
            for (ngram, count) in vec_hyp[n].items():
                # vrama91 : added clipping
                val[n] += min(vec_hyp[n][ngram],
                              vec_ref[n][ngram]) * vec_ref[n][ngram]

            if (norm_hyp[n] != 0) and (norm_ref[n] != 0):
                val[n] /= (norm_hyp[n] * norm_ref[n])

            assert not math.isnan(val[n])
            # vrama91: added a length based gaussian penalty
            val[n] *= np.e**(-(delta**2) / (2 * self.sigma**2))
        return val

    # compute log reference length
    self.ref_len = np.log(float(len(self.crefs)))

    scores = []
    for test, refs in zip(self.ctest, self.crefs):
        # compute vector for test captions
        vec, norm, length = counts2vec(test)
        # compute vector for ref captions
        score = np.array([0.0 for _ in range(self.n)])
        for ref in refs:
            vec_ref, norm_ref, length_ref = counts2vec(ref)
            score += sim(vec, vec_ref, norm, norm_ref, length, length_ref)
        # change by vrama91 - mean of ngram scores, instead of sum
        score_avg = np.mean(score)
        # divide by number of references
        score_avg /= len(refs)
        # multiply score by 10
        score_avg *= 10.0
        # append score of an image to the score list
        scores.append(score_avg)
    return scores</code></pre>
</details>
</dd>
<dt id="pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_doc_freq"><code class="name flex">
<span>def <span class="ident">compute_doc_freq</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute term frequency for reference data.
This will be used to compute idf (inverse document frequency later)
The term frequency is stored in the object
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_doc_freq(self):
    &#39;&#39;&#39;
    Compute term frequency for reference data.
    This will be used to compute idf (inverse document frequency later)
    The term frequency is stored in the object
    :return: None
    &#39;&#39;&#39;
    for refs in self.crefs:
        # refs, k ref captions of one image
        for ngram in set([ngram for ref in refs for (ngram, count) in ref.items()]):
            self.document_frequency[ngram] += 1</code></pre>
</details>
</dd>
<dt id="pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_score"><code class="name flex">
<span>def <span class="ident">compute_score</span></span>(<span>self, option=None, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_score(self, option=None, verbose=0):
    # compute idf
    self.compute_doc_freq()
    # assert to check document frequency
    assert len(self.ctest) &gt;= max(self.document_frequency.values())
    # compute cider score
    score = self.compute_cider()
    return np.mean(np.array(score)), np.array(score)</code></pre>
</details>
</dd>
<dt id="pysimt.cocoeval.cider.cider_scorer.CiderScorer.cook_append"><code class="name flex">
<span>def <span class="ident">cook_append</span></span>(<span>self, test, refs)</span>
</code></dt>
<dd>
<div class="desc"><p>called by constructor and <strong>iadd</strong> to avoid
creating new instances.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cook_append(self, test, refs):
    &#39;&#39;&#39;called by constructor and __iadd__ to avoid
    creating new instances.&#39;&#39;&#39;

    if refs is not None:
        self.crefs.append(cook_refs(refs))
        if test is not None:
            self.ctest.append(cook_test(test))  # N.B.: -1
        else:
            # lens of crefs and ctest have to match
            self.ctest.append(None)</code></pre>
</details>
</dd>
<dt id="pysimt.cocoeval.cider.cider_scorer.CiderScorer.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>copy the refs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self):
    &#39;&#39;&#39; copy the refs.&#39;&#39;&#39;
    new = CiderScorer(n=self.n)
    new.ctest = copy.copy(self.ctest)
    new.crefs = copy.copy(self.crefs)
    return new</code></pre>
</details>
</dd>
<dt id="pysimt.cocoeval.cider.cider_scorer.CiderScorer.size"><code class="name flex">
<span>def <span class="ident">size</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def size(self):
    assert len(self.crefs) == len(self.ctest), \
        &#34;refs/test mismatch! %d&lt;&gt;%d&#34; % (len(self.crefs), len(self.ctest))
    return len(self.crefs)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysimt.cocoeval.cider" href="index.html">pysimt.cocoeval.cider</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.cook_refs" href="#pysimt.cocoeval.cider.cider_scorer.cook_refs">cook_refs</a></code></li>
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.cook_test" href="#pysimt.cocoeval.cider.cider_scorer.cook_test">cook_test</a></code></li>
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.precook" href="#pysimt.cocoeval.cider.cider_scorer.precook">precook</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pysimt.cocoeval.cider.cider_scorer.CiderScorer" href="#pysimt.cocoeval.cider.cider_scorer.CiderScorer">CiderScorer</a></code></h4>
<ul class="two-column">
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_cider" href="#pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_cider">compute_cider</a></code></li>
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_doc_freq" href="#pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_doc_freq">compute_doc_freq</a></code></li>
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_score" href="#pysimt.cocoeval.cider.cider_scorer.CiderScorer.compute_score">compute_score</a></code></li>
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.CiderScorer.cook_append" href="#pysimt.cocoeval.cider.cider_scorer.CiderScorer.cook_append">cook_append</a></code></li>
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.CiderScorer.copy" href="#pysimt.cocoeval.cider.cider_scorer.CiderScorer.copy">copy</a></code></li>
<li><code><a title="pysimt.cocoeval.cider.cider_scorer.CiderScorer.size" href="#pysimt.cocoeval.cider.cider_scorer.CiderScorer.size">size</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>